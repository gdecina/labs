{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h1/hrjhnsw55w3fh7wq8fc7_bcm0000gn/T/ipykernel_1137/2621796662.py:18: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  household_power_consumption = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initializing Metal backend\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Importing dataset\n",
    "# Data available here : https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption\n",
    "household_power_consumption = pd.read_csv(\n",
    "    \"household_power_consumption.txt\",\n",
    "    sep = \";\", parse_dates = {\"datetime\":[\"Date\", \"Time\"]}, low_memory = False, \n",
    "    na_values = [\"nan\", \"?\"])\n",
    "\n",
    "# Set datetime as index\n",
    "household_power_consumption.set_index(\"datetime\", inplace = True)\n",
    "\n",
    "# Checking for NaN values\n",
    "household_power_consumption.isna().values.any()\n",
    "\n",
    "# Filling missing values\n",
    "household_power_consumption.interpolate(inplace = True)\n",
    "\n",
    "# Normalizing variables\n",
    "scaler = MinMaxScaler()\n",
    "household_pc_scaled = scaler.fit_transform(household_power_consumption)\n",
    "\n",
    "# Putting normalized data in a DataFrame\n",
    "household_pc_scaled = pd.DataFrame(household_pc_scaled,\n",
    "                                   columns=household_power_consumption.columns, \n",
    "                                   index=household_power_consumption.index)\n",
    "\n",
    "# Splitting our sample\n",
    "household_pc_training = household_pc_scaled.sample(frac = 0.8, random_state = 123456)\n",
    "household_pc_validation = household_pc_scaled.drop(household_pc_training.index)\n",
    "\n",
    "# Creating sequences for time-series forecasting\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    _summary_\n",
    "    This function creates sequences with a fixed length to use as input in a model.\n",
    "    It allows us to use the past n (as set by seq_length) observations to predict the n+1 one.\n",
    "    The n observations are stored in xs, the n+1 one is stored in ys.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): input data\n",
    "        seq_length (int): length of data used to predict the next value\n",
    "\n",
    "    Returns:\n",
    "        np.array, np.array: two arrays containing the sequences\n",
    "    \"\"\"    \n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data.iloc[i:(i+seq_length)].values\n",
    "        y = data.iloc[i+seq_length][\"Global_active_power\"]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Generating the sequences\n",
    "seq_n = 24\n",
    "X_train, y_train = create_sequences(household_pc_scaled.drop(household_pc_validation.index), seq_n)\n",
    "X_test, y_test = create_sequences(household_pc_validation, seq_n)\n",
    "\n",
    "# Converting data to PyTorch tensors\n",
    "X_train_tensors = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensors = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test_tensors = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensors = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Creating data loaders\n",
    "hh_pc_train = TensorDataset(X_train_tensors, y_train_tensors)\n",
    "hh_pc_test = TensorDataset(X_test_tensors, y_test_tensors)\n",
    "train_loader = DataLoader(hh_pc_train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(hh_pc_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.0009010808395075919\n",
      "Epoch 2/50, Loss: 0.0006832155014763273\n",
      "Epoch 3/50, Loss: 0.0006528048261794014\n",
      "Epoch 4/50, Loss: 0.0006362979056989979\n",
      "Epoch 5/50, Loss: 0.0006231122805455548\n",
      "Epoch 6/50, Loss: 0.0006148620469378081\n",
      "Epoch 7/50, Loss: 0.0006079577112587047\n",
      "Epoch 8/50, Loss: 0.0006019563124593182\n",
      "Epoch 9/50, Loss: 0.000596521514430913\n",
      "Epoch 10/50, Loss: 0.0005919807101360117\n",
      "Epoch 11/50, Loss: 0.0005868797766897156\n",
      "Epoch 12/50, Loss: 0.000582985135677321\n",
      "Epoch 13/50, Loss: 0.0005801619826410436\n",
      "Epoch 14/50, Loss: 0.000577361868905058\n",
      "Epoch 15/50, Loss: 0.000573446018309402\n",
      "Epoch 16/50, Loss: 0.0005720336472729457\n",
      "Epoch 17/50, Loss: 0.000570553282401576\n",
      "Epoch 18/50, Loss: 0.0005683819362098576\n",
      "Epoch 19/50, Loss: 0.0005666210603981051\n",
      "Epoch 20/50, Loss: 0.0005643350128641911\n",
      "Epoch 21/50, Loss: 0.0005629249126075182\n",
      "Epoch 22/50, Loss: 0.0005627217165766351\n",
      "Epoch 23/50, Loss: 0.000560680980520996\n",
      "Epoch 24/50, Loss: 0.0005603657263804537\n",
      "Epoch 25/50, Loss: 0.0005580664584881417\n",
      "Epoch 26/50, Loss: 0.0005572199170182104\n",
      "Epoch 27/50, Loss: 0.0005575489658041012\n",
      "Epoch 28/50, Loss: 0.0005545968198545465\n",
      "Epoch 29/50, Loss: 0.0005530031777918119\n",
      "Epoch 30/50, Loss: 0.0005529390644998112\n",
      "Epoch 31/50, Loss: 0.0005530973028056715\n",
      "Epoch 32/50, Loss: 0.0005520649129431295\n",
      "Epoch 33/50, Loss: 0.0005514886432643792\n",
      "Epoch 34/50, Loss: 0.0005516459759339046\n",
      "Epoch 35/50, Loss: 0.0005503524694831428\n",
      "Epoch 36/50, Loss: 0.000551708783339958\n",
      "Epoch 37/50, Loss: 0.0005484098957411801\n",
      "Epoch 38/50, Loss: 0.0005495138725670583\n",
      "Epoch 39/50, Loss: 0.0005476324817753031\n",
      "Epoch 40/50, Loss: 0.0005495182313403832\n",
      "Epoch 41/50, Loss: 0.0005475794641381745\n",
      "Epoch 42/50, Loss: 0.0005607175633404976\n",
      "Epoch 43/50, Loss: 0.0005638666687652523\n",
      "Epoch 44/50, Loss: 0.0005471895110475381\n",
      "Epoch 45/50, Loss: 0.0005473515414708896\n",
      "Epoch 46/50, Loss: 0.0005464510368275999\n",
      "Epoch 47/50, Loss: 0.0005452119352684336\n",
      "Epoch 48/50, Loss: 0.0005440362561293748\n",
      "Epoch 49/50, Loss: 0.0005439522937084798\n",
      "Epoch 50/50, Loss: 0.0005442229028613658\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest MSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m actuals, predictions, mse\n\u001b[0;32m---> 62\u001b[0m actuals, predictions, mse \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Graphing the results\u001b[39;00m\n\u001b[1;32m     65\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "Cell \u001b[0;32mIn[21], line 54\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     53\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[0;32m---> 54\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     55\u001b[0m         actuals\u001b[38;5;241m.\u001b[39mappend(y_batch\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     56\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(predictions)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# Model construction\n",
    "class EnergyConsumptionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(EnergyConsumptionModel, self).__init__()\n",
    "        self.fc0 = nn.Linear(input_dim, 100)\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.lstm1 = nn.LSTM(50, 50, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.bn = nn.BatchNorm1d(50)\n",
    "        self.fc2 = nn.Linear(50, 25)\n",
    "        self.fc3 = nn.Linear(25, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        lstm_out, _ = self.lstm1(x)\n",
    "        lstm_out = lstm_out[:, -1, :] # Output extraction from LSTM layer\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_out = self.bn(lstm_out)\n",
    "        x = F.relu(self.fc2(lstm_out))\n",
    "        out = self.fc3(x)\n",
    "        return out\n",
    "\n",
    "# Initialization\n",
    "model = EnergyConsumptionModel(X_train.shape[2]).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, \"min\", factor=0.1, patience=5)\n",
    "\n",
    "# Model training\n",
    "def train_model(model, train_loader, criterion, optimizer, scheduler, epochs = 20):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, scheduler, epochs=50)\n",
    "\n",
    "# Model evaluation\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            predictions.append(outputs.squeeze().cpu().numpy())\n",
    "            actuals.append(y_batch.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions)\n",
    "    actuals = np.concatenate(actuals)\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    print(f'Test MSE: {mse}')\n",
    "    return actuals, predictions, mse\n",
    "\n",
    "actuals, predictions, mse = evaluate_model(model, test_loader)\n",
    "\n",
    "# Graphing the results\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(actuals, label=\"Actuals\")\n",
    "plt.plot(predictions, label=\"Predictions\")\n",
    "plt.legend()\n",
    "plt.title(\"Energy Consumption Forecasting\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Energy Consumption\")\n",
    "plt.savefig(\"nn_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            predictions.append(outputs.squeeze().cpu().numpy())\n",
    "            actuals.append(y_batch.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions)\n",
    "    actuals = np.concatenate(actuals)\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    print(f'Test MSE: {mse}')\n",
    "    return actuals, predictions, mse\n",
    "\n",
    "actuals, predictions, mse = evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
